
*This document contains an attempt at answering the questions from the 2016 CS4001 Fuzzy Logic exam*

# 2016

## 2016 Q1

### Q1a)

The intersection of a crisp set and its complement is the null/empty set. In most cases, the intersection of a fuzzy subset and its complement is not the null set. This is because the membership grades of Ā are 𝝁<sub>Ā</sub>(x) == 1-𝝁<sub>A</sub>(x).

### Q1b)

|Requirement|Satisfaction|
|---|---|
|Boundary|<code>T(0,0) = 0</code> & <code>T(a,1) = T(1,a) = a</code>|
|Monotonicity|`T(a,b) < T(c,d) if a<c & b<d`|
|Commutativity|<code>T(x,y) = T(y,x)</code>|
|Associativity|<code>T(x, T(y,z)) = T(T(x,z),y)</code>|

### Q1c)

The three most cited functions in the literature are:

**T-Norm**:  
Minimum: <code>T<sub>min</sub> = min(a,b) = a 𝚲 b;</code>  
Algebraic Product: <code>T<sub>AP</sub> = ab;</code>  
Bounded Product: <code>T<sub>BP</sub> = 0 V (a + b - 1);</code>  

**S-Norm**:  
Maximum: <code>S(a,b) = max(a,b) = a V b;</code>  
Algebraic Sum: <code>S(a,b) = a + b - ab;</code>  
Bounded Sum: <code>S(a,b) = 1 𝚲 (a + b);</code>  

### Q1d)

The one main implication of using these triangular norms in fuzzy decision making is that defuzzification cannot be uniquely specified.

It can be verified that, for example by choosing different values of *a* & *b*, the following inequalities hold:  
<code>T<sub>BP</sub> ≤ T<sub>AP</sub> ≤ T<sub>mind</sub>;</code>  
<code>S<sub>max</sub>(a,b) ≤ S<sub>AP</sub>(a,b) ≤ S<sub>BP</sub>(a,b);</code>  
These requirements for T-norm & T-conorm functions cannot uniquely determine the classical fuzzy intersection and union (namely the min & max operators).

## 2016 Q2

### 2a)

**Fuzzification** is the mapping of information onto the term-set of a linguistic variable.

**Inference** is the invoking of rules in a knowledge base systematically to determine which rules are fired and to what degree.

**Composition** is an averaging procedure used to compute the effectiveness of each rule.

**Defuzzification** is the process of converting fuzzy values onto crisp numbers.

### 2b)

Here are the full membership functions:

**Note to student readers: It takes a long time to write this out and the question does not ask for it, but I thought it might help your understanding for me to put it here.**

**Excellent Salary:**  
<code>𝝁<sub>Excellent Salary</sub>(x) = 0 if x ≤ 90</code>  
<code>𝝁<sub>Excellent Salary</sub>(x) = 1-(120-x)/(120-90) if 90 < x < 120</code>  
<code>𝝁<sub>Excellent Salary</sub>(x) = 1 if x ≥ 120</code>  

**Good Salary:**  
<code>𝝁<sub>Good Salary</sub>(x) = 0 if x ≥ 100</code>  
<code>𝝁<sub>Good Salary</sub>(x) = 1-(x-75)/(100-75) if 75 < x < 100</code>
<code>𝝁<sub>Good Salary</sub>(x) = (x-50)/(75-50) if 50 < x ≤ 75</code>  
<code>𝝁<sub>Good Salary</sub>(x) = 0 if x ≤ 50</code>   

**Poor Salary:**  
<code>𝝁<sub>Poor Salary</sub>(x) = 1 if x ≤ 10</code>  
<code>𝝁<sub>Poor Salary</sub>(x) = (60-x)/(60-10) if 10 < x < 60</code>  
<code>𝝁<sub>Poor Salary</sub>(x) = 0 if x ≥ 60</code>

**Small Debt:**  
<code>𝝁<sub>Small Debt</sub>(x) = 1 if x ≤ 10</code>  
<code>𝝁<sub>Small Debt</sub>(x) = (50-x)/(50-10) if 10 < x < 50</code>  
<code>𝝁<sub>Small Debt</sub>(x) = 0 if x ≥ 50</code>  

**Large Debt:**   
<code>𝝁<sub>Large Debt</sub>(x) = 0 if x ≤ 15</code>  
<code>𝝁<sub>Large Debt</sub>(x) = 1-(60-x)/(60-15) if 15 < x < 60</code>   
<code>𝝁<sub>Large Debt</sub>(x) = 1 if x ≥ 60</code>  

**Low Risk:**  
<code>𝝁<sub>Low Risk</sub>(x) = 1 if x ≤ 20</code>  
<code>𝝁<sub>Low Risk</sub>(x) = (40-x)/(40-20) if 20 < x < 40</code>  
<code>𝝁<sub>Low Risk</sub>(x) = 0 if x ≥ 40</code>  

**Medium Risk:**  
<code>𝝁<sub>Medium Risk</sub>(x) = 0 if x ≥ 80</code>  
<code>𝝁<sub>Medium Risk</sub>(x) = 1-(x-60)/(80-60) if 60 < x < 80</code>  
<code>𝝁<sub>Medium Risk</sub>(x) = 1 if 40 ≤ x ≤ 60</code>  
<code>𝝁<sub>Medium Risk</sub>(x) = (x-20)/(40-20) if 20 < x < 40</code>   
<code>𝝁<sub>Medium Risk</sub>(x) = 0 if x ≤ 20</code>   

**High Risk:**  
<code>𝝁<sub>High Risk</sub>(x) = 0 if x ≤ 60</code>  
<code>𝝁<sub>High Risk</sub>(x) = 1-(80-x)/(80-60) if 60 < x < 80</code>  
<code>𝝁<sub>High Risk</sub>(x) = 1 if x ≥ 80</code>  

1. Fuzzification:

*salary=140K & debts=60K*

Term|Linguistic Variable|Membership Value
---|---|---
s|Excellent_Salary(s)|1
s|Good_Salary(s)|0
s|Poor_Salary(s)|0
d|Small_Debt(d)|0
d|Large_Debt(d)|1

2. Inference & Composition:

*salary=140K & debts=60K*

|Rule number|Rule antecedent|Firing Degree|
|---|---|---|
|Rule 1|Excellent Salary OR Small Debts|1|
|Rule 2|Good Salary AND Large Debts|0|
|Rule 3|Poor Salary|0|

Rule 1 is the only rule that fires:  
"IF SALARY is EXCELLENT OR DEBTS are SMALL THEN RISK is LOW"

Because only Rule 1 fires, we know that RISK is LOW and that we should use the membership function <code>𝝁<sub>Low Risk</sub>(x)</code> to calculate the output.

3. Defuzzification:

|x|<code>𝝁<sub>Low Risk</sub>(x)</code>|
|---|---|
|0|1|
|10|1|
|20|1|
|30|0.5|
|40|0|
|50|0|
|60|0|
|70|0|
|80|0|
|90|0|
|100|0|

The crisp value for the Mean of Maxima method is:

<code>( Σ alpha * x ) / ( Σ alpha )</code>

*where <code>alpha</code> is the maximum output value of the fuzzy set.*

The set is given an alpha level cut so that only values of x that give the maximum output value are used.

Using the above equation for the MOM method:  

`( 0*1 + 10*1 + 20*1 ) / ( 1 + 1 + 1 ) == 10`

Therefore having used the MOM method, the output value is 10 and the associated risk with Jim is 10%.

### 2c)

Following on from the Fuzzification, Inference & Composition in Q3b, here is the Defuzzification using the Centre of Area method:

|x|<code>𝝁<sub>Low Risk</sub>(x)</code>|
|---|---|
|0|1|
|10|1|
|20|1|
|30|0.5|
|40|0|
|50|0|
|60|0|
|70|0|
|80|0|
|90|0|
|100|0|

The crisp value for the Centre of Area method is:

<code>( Σ 𝝁<sub>Low Risk</sub>(x) * x ) / 𝝁<sub>Low Risk</sub>(x)</code>

*For the Centre of Area method, all values of x are used.*

`( 0*1 + 10*1 + 20*1 + 30*0.5 + (40+50+60+70+80+90+100)*0 ) / ( 1 + 1 + 1 + 0.5 + 0 + 0 + 0 + 0 + 0 + 0 + 0 ) == 12.857`

Therefore having used the COA method, the output value is 12.857 and the associated risk with Jim is 12.857%.

|Method|Output Value|
|---|---|
|MOM|10%|
|COA|12.857%|

The output values are different when the MOM or COA Defuzzification methods are used. COA generally gives higher results than MOM.

COA is more accurate than MOM as it makes use of every input value and does not perform an alpha level cut.  MOM is faster than COA because of its alpha level cut, and this can make it more desirable in Real-time systems.

## 2016 Q3

### 3ai)

**Mamdani**: <code>IF X is <sub>X</sub>(X) THEN Y is <sub>𝝁</xub>(Y)</code>  
**TSK**: <code>IF X is <sub>X</sub>(X) THEN Y = f(X)</code>  

### 3ai)

**Note to student reader: If it isn't very clear how I came up with the following answer, it's because I took it from the [model answer](https://tcd.blackboard.com/bbcswebdav/pid-960051-dt-content-rid-4009260_1/courses/CS4001-A-Y-201718/Problems%20and%20Model%20Solutions%20for%20Fuzzy%20Logic%20and%20Control.pdf#page=8) :(**

**Mamdani**: <code><sub>X</sub>(X)</code> & <code><sub>𝝁</xub>(Y)</code> are membership functions of the terms X & Y.  
**TSK**: <code><sub>X</sub>(X)</code> is a membership function of term X, and Y is a linear function of X.

### 3b)

**Note to student readers: A model answer has not been found for this paper, so I have not been able to verify this answer:**

**Takagi-Sugeno-Kang Controllers**' rules contain membership functions for the antecedants & linear functions in the consequents. The linear functions that represent the outputs have constants that need to be defined. The implication of TSK for a fuzzy logic system is that the creators of the system need to define these constants.

Another implication is that TSK is not as intuitive as Mamdani systems because of its use of linear functions in the output instead of membership functions of Fuzzy Terms.

### 3c)

#### 3ci)

<code>𝝁<sub>COLD</sub>(1) = 0.09</code>  
<code>𝝁<sub>COOL</sub>(1) = 0.08</code>  
<code>𝝁<sub>PLEASANT</sub>(1) = 0</code>  
<code>𝝁<sub>WARM</sub>(1) = 0</code>  
<code>𝝁<sub>HOT</sub>(1) = 0</code>  

Rule 1 has firing degree 0.9.   
Rule 2 has firing degree 0.08.  

SPEED = `(0*0.09 + 30*0.08)/(0.9+0.08) =  2.449)`

#### 3cii)

<code>𝝁<sub>COLD</sub>(10) = 0</code>  
<code>𝝁<sub>COOL</sub>(10) = 0.8</code>  
<code>𝝁<sub>PLEASANT</sub>(10) = 0</code>  
<code>𝝁<sub>WARM</sub>(10) = 0</code>  
<code>𝝁<sub>HOT</sub>(10) = 0</code>  

Rule 2 has firing degree 0.08.  

SPEED = `(30*0.08)/(0.8) = 30`

#### 3ciii)

<code>𝝁<sub>COLD</sub>(16) = 0</code>  
<code>𝝁<sub>COOL</sub>(16) = 0.3</code>  
<code>𝝁<sub>PLEASANT</sub>(16) = 0.4</code>  
<code>𝝁<sub>WARM</sub>(16) = 0</code>  
<code>𝝁<sub>HOT</sub>(16) = 0</code>  

Rule 2 has firing degree 0.3.  
Rule 3 has firing degree 0.4.  

SPEED = `(30*0.3 + 50*0.4)/(0.3+0.4) = 41.428`

## 2016 Q4

### 4a)

To compute the membership functions, I will be using the exponential of half the difference between the ancestor and the daughter species, as suggested:

||Parent/Daughter|Grandparent/Daughter|Great Grandparent/Daughter|Great Great-Grandparent/Daughter|
|-------------|---|---|---|---|
|Distance     |  1|  2|  3|  4|
|Belongingness|exp(-0.5)=0.61|exp(-1)=0.367|exp(-1.5)=0.223|exp(-2)=0.135|

`Great Great-Grandparent =  {0.135/Pacific Lamprey, 0.135/Arctic Lamprey, 0.135/Atlantic Salmon, 0.135/Pacific Salmon, 0.135/Blue Shark, 0.135/White Shark, 0.135/Non-snake Lizard, 0.135/Snake-like Lizards}`

`Great Grandparent =  {0/Pacific Lamprey, 0/Arctic Lamprey, 0.223/Atlantic Salmon, 0.223/Pacific Salmon, 0.223/Blue Shark, 0.223/White Shark, 0.223/Non-snake Lizard, 0.223/Snake-like Lizards}`

`Grandparent =  {0/Pacific Lamprey, 0/Arctic Lamprey, 0.367/Atlantic Salmon, 0.367/Pacific Salmon, 0/Blue Shark, 0/White Shark, 0.367/Non-snake Lizard, 0.367/Snake-like Lizards}`

`Salmon-Parent =  {0/Pacific Lamprey, 0/Arctic Lamprey, 0.61/Atlantic Salmon, 0.61/Pacific Salmon, 0/Blue Shark, 0/White Shark, 0/Non-snake Lizard, 0/Snake-like Lizards}`

`Lizard-parent =  {0/Pacific Lamprey, 0/Arctic Lamprey, 0/Atlantic Salmon, 0/Pacific Salmon, 0/Blue Shark, 0/White Shark, 0.61/Non-snake Lizard, 0.61/Snake-like Lizards}`

### 4b)

**Salmon-Parent:**  
Cardinality: `0.61+0.61=1.22`   
Core:  
Support: Atlantic Salmon, Pacific Salmon

**Lizard-Parent:**  
Cardinality: `0.61+0.61=1.22`  
Core:  
Support: Non-snake Lizard, Snake-like Lizards

**Grandparent:**  
Cardinality: `0.367+0.367+0.367+0.367=1.468`  
Core:  
Support: Atlantic Salmon, Pacific Salmon, Non-snake Lizard, Snake-like Lizards

**Great Grandparent:**  
Cardinality: `0.233+0.233+0.233+0.233+0.233+0.233=1.398`  
Core:  
Support: Atlantic Salmon, Pacific Salmon, Blue Shark, White Shark, Non-snake Lizard, Snake-like Lizards

**Great Great-Grandparent:**  
Cardinality: `0.135+0.135+0.135+0.135+0.135+0.135+0.135+0.135=1.08`  
Core: Galago  
Support: Pacific Lamprey, Arctic Lamprey, Atlantic Salmon, Pacific Salmon, Blue Shark, White Shark, Non-snake Lizard, Snake-like Lizards  

## 2016 Q5

### 5a)

|STEP|Description|Equations|
|---|---|---|
|1|Set initial weights *w1* & *w2* & the bias 𝞡 to random values||
|2|Compute the weighted sum|`𝞢 = x1*w1 + x2*w2 + 𝞡`|
|3|Calculate the output using a 𝝳-function|`y(i) = 𝝳(x1*w1 + x2*w2 + 𝞡)`<br>`𝝳(x) = 1, if x > 0;`<br>`𝝳(x) = 0, if x ≤ 0;`|
|4|Compute the error *e* which is the difference between the actual output *y* and the desired output *y_desired*.|`e(i) = y_desired - y(i)`|
|5a|If the errors during a training epoch are all zero then stop.||
|5b|If the errors during a training epoch are not all zero, then update the weights|`wj(i+1) = wj(i) + 𝝰*xj*e(i), j=1,2;`<br>`i = i + 1;`|
|5c|Go to step 2||

### 5b)

**Epoch 1**

 X1| X2|Desired output|  w1|  w2| Sum|Actual output|Error|  w1|  w2
---|---|--------------|----|----|----|-------------|-----|----|----
  0|  0|             0| 0.3|-0.1|-0.3|            0|    0| 0.3|-0.1
  1|  0|             1| 0.3|-0.1|   0|            0|    1| 0.5|-0.1
  0|  1|             1| 0.5|-0.1|-0.4|            0|    1| 0.5| 0.1
  1|  1|             1| 0.5| 0.1| 0.3|            1|    0| 0.5| 0.1

**Epoch 2**

 X1| X2|Desired output|  w1|  w2| Sum|Actual output|Error|  w1|  w2
---|---|--------------|----|----|----|-------------|-----|----|----
  0|  0|             0| 0.5| 0.1|-0.3|            0|    0| 0.5| 0.1
  1|  0|             1| 0.5| 0.1| 0.2|            1|    0| 0.5| 0.1
  0|  1|             1| 0.5| 0.1|-0.2|            0|    1| 0.5| 0.3
  1|  1|             1| 0.5| 0.3| 0.8|            1|    0| 0.5| 0.3

**Epoch 3**

 X1| X2|Desired output|  w1|  w2| Sum|Actual output|Error|  w1|  w2
---|---|--------------|----|----|----|-------------|-----|----|----
  0|  0|             0| 0.5| 0.3|-0.3|            0|    0| 0.5| 0.3
  1|  0|             1| 0.5| 0.3| 0.2|            1|    0| 0.5| 0.3
  0|  1|             1| 0.5| 0.3|   0|            0|    1| 0.5| 0.5
  1|  1|             1| 0.5| 0.5|   7|            1|    0| 0.5| 0.5

**Epoch 4**

 X1| X2|Desired output|  w1|  w2| Sum|Actual output|Error|  w1|  w2
---|---|--------------|----|----|----|-------------|-----|----|----
  0|  0|             0| 0.5| 0.5| 0.3|            0|    0| 0.5| 0.5
  1|  0|             1| 0.5| 0.5| 0.2|            1|    0| 0.5| 0.5
  0|  1|             1| 0.5| 0.5| 0.2|            1|    0| 0.5| 0.5
  1|  1|             1| 0.5| 0.5|   7|            1|    0| 0.5| 0.5

### 5c)

The XOR gate cannot be modelled by simple perceptron because it does not belong to the set of linearly separable problems.

A single perceptron can represent a line in an input space where all inputs below have one output value and all inputs above have another. However the input space of an XOR gate can not be divided by a line to get all of the inputs related to zero on one side and all of the inputs related to one on the other.

Because of this; the XOR gate can not be modelled by a single perceptron.

### 5d)

In order to model XOR gate we need to design a neuro-fuzzy system with one hidden layer. In this system, first layer would comprise inputs x1 and x2 and a bias. Two input nodes together with bias would all be connected to one neuron in the hidden layer. Another neuron in the hidden layer would be the bias. All neurons from the hidden layer are connected to the one neuron in the output layer:

<img src="./assets/xor-gate-system-architecture.png"/>
